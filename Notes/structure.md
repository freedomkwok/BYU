           Input
             â†“
        [ Stem (optional) ]
             â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Backbone   â”‚  â† feature extractor (multi-scale, deep)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Neck       â”‚  â† multi-scale fusion, refinement
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Head       â”‚  â† prediction layer (e.g., object boxes)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
         [ Postprocessing ]  â† NMS, decoding, thresholds

ğŸ§  Each Block and Its Categories (with Common Components)
1. ğŸ§± Backbone â€” feature extractor
    Typically CNNs, Transformers, or hybrids
    Generates multi-resolution features (P2â€“P5)
ğŸ”„ Examples of Backbone Modules:
| Type              | Component Names                    | Notes                           |
| ----------------- | ---------------------------------- | ------------------------------- |
| CNN-based         | ResNet, CSPNet, ELAN, EfficientNet | Most YOLOs use CSP or ELAN      |
| Transformer-based | ViT, Swin, DeiT, ConvNeXt, PVT     | Used in DETR, YOLO-MS           |
| Hybrid            | CMT, InternImage, MobileViT        | Combines convs and attention    |
| Multi-branch      | **RepHMS**, ELAN, MSBlock          | Feature splitting, multi-kernel |
| Lightweight       | ShuffleNet, MobileNet, GhostNet    | Used in mobile variants         |

2. ğŸ”€ Neck â€” feature fusion/refinement
Combines multi-scale outputs from the backbone
Improves context and spatial detail before detection
| Type            | Component Names                    | Notes                                     |
| --------------- | ---------------------------------- | ----------------------------------------- |
| Standard FPN    | FPN, PANet, PAFPN                  | Top-down or bottom-up                     |
| Attention FPN   | BiFPN, HRFPN, **GDFPN**, **MAFPN** | Uses attention or gather-distribute       |
| Transformer FPN | TransformerNeck, RepGFPN, TPFPN    | Uses self-attention to fuse               |
| Specialized     | **SAF**, **AAF** (MHAF-YOLO)       | Shallow & deep fusion in separate streams |
| Slim necks      | LiteNeck, SlimFPN                  | Used for lightweight variants             |

3. ğŸ¯ Head â€” detection, classification, segmentation
Converts final feature map into task-specific predictions
ğŸ”„ Examples of Head Modules:
| Type                | Component Names                       | Notes                                   |
| ------------------- | ------------------------------------- | --------------------------------------- |
| Anchor-based        | YOLOv3 Head, RetinaNet, SSD Head      | Needs predefined anchors                |
| Anchor-free         | YOLOv4/v8 Head, FCOS, CenterNet       | Direct regression                       |
| Transformer decoder | DETR Head, DINO Head                  | Query-based detection                   |
| Self-refining head  | **D-FINE**, ATSS Head, PAA            | Uses additional branches for refinement |
| Segmentation heads  | SOLO, Mask R-CNN, SegFormer, YOLO-seg | Pixel-level prediction                  |

4. âœ¨ Attention modules â€” can be injected anywhere
Not full layers â€” plug-in modules that enhance representation
ğŸ”„ Common Attention Components:
| Type                 | Component Names                        | Typical Location    |
| -------------------- | -------------------------------------- | ------------------- |
| Channel attention    | **SE**, **ECA**, GE-Block              | After conv blocks   |
| Spatial attention    | CBAM, BAM                              | After conv or neck  |
| Transformer blocks   | MultiHeadAttention, TransformerEncoder | In neck or backbone |
| Contextual attention | DRSA, LKA, Bi-Level Attention          | Advanced variants   |

5. ğŸ” Miscellaneous (connectors, helpers)
| Type                | Examples                          | Usage                   |
| ------------------- | --------------------------------- | ----------------------- |
| Downsample/Upsample | Interpolate, ConvDown, DeformDown | Between FPN levels      |
| Fusion              | Add, Concat, BiFusion             | Within neck or head     |
| Norm/Activation     | LayerNorm, BatchNorm, SiLU        | All layers              |
| Regularization      | DropBlock, DropPath               | Stabilize deep networks |

ğŸ§¬ Typical Component Flow (e.g., YOLO-like + Attention)
Input
  â†“
Stem (Conv + BN + SiLU)
  â†“
[Backbone]
  â””â”€â”€ RepHMS / ELAN / CSP
       â†“
[Attention]
  â””â”€â”€ SE / CBAM / MHA
       â†“
[Neck]
  â””â”€â”€ FPN / PAN / GDFPN / MAFPN
       â†“
[Head]
  â””â”€â”€ YOLO Head / Transformer Decoder
       â†“
Postprocess (NMS)

âœ… Summary Table
| Category  | Examples                                                      |
| --------- | ------------------------------------------------------------- |
| Backbone  | CSPNet, ELAN, RepHMS, MobileViT, Swin, PVT                    |
| Neck      | FPN, PAN, PAFPN, BiFPN, GDFPN, MAFPN, TransformerNeck         |
| Head      | YOLO Head, FCOS, CenterNet, D-FINE, DETR Head, SegFormer Head |
| Attention | SE, CBAM, ECA, MHA, LKA, DRSA, TransformerEncoderLayer        |
| Utility   | Upsample, Concat, Add, BatchNorm, DropPath                    |


âš ï¸ But itâ€™s not always the best because...
âŒ 1. It may destroy fine-grained detail
    In tasks like segmentation, pose estimation, or small object detection,
    Stride-2 convs might discard important spatial info (edges, corners, small features)
    Example: Downsampling a 16Ã—16 patch to 8Ã—8 may lose the only visible tail of a small object.

âŒ 2. Pooling (e.g. MaxPool2d) can preserve strong activations
    MaxPooling preserves high-response areas (e.g. object centers)
    Helpful in lightweight models (e.g. MobileNet) where simplicity matters

âŒ 3. Average Pooling is more stable for global context
    Useful in global average pooling layers at the end of a network
    Doesnâ€™t introduce learned bias

âŒ 4. Interpolated downsampling (e.g. bilinear + conv) is smoother
    Often used in attention-based or hybrid models
    Keeps shape consistency across layers
    Used in some Transformer-FPN hybrids