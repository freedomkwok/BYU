{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91249,"databundleVersionId":11294684,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":11986142,"sourceType":"datasetVersion","datasetId":7538808},{"sourceId":11986780,"sourceType":"datasetVersion","datasetId":7539261},{"sourceId":11986945,"sourceType":"datasetVersion","datasetId":7539377},{"sourceId":11988291,"sourceType":"datasetVersion","datasetId":7540294},{"sourceId":11988315,"sourceType":"datasetVersion","datasetId":7540310},{"sourceId":226368929,"sourceType":"kernelVersion"},{"sourceId":139093,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":117776,"modelId":141013},{"sourceId":139474,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":118113,"modelId":141350}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BYU Locating Flagellar Motors\n\n## YOLO Model Training Notebook\n\nThis is the third notebook in a series for the BYU Locating Bacterial Flagellar Motors 2025 Kaggle challenge. This notebook handles the training of YOLOv8 object detection models on our prepared dataset.\n\n### Notebook Series:\n1. **[Parse Data](https://www.kaggle.com/code/andrewjdarley/parse-data)**: Extracting and preparing 2D slices containing motors to make a YOLO dataset\n2. **[Visualize Data](https://www.kaggle.com/code/andrewjdarley/visualize-data)**: Exploratory data analysis and visualization of annotated motor locations\n3. **Train YOLO (Current)**: Fine tuning an YOLOv8 object detection model on the prepared dataset\n4. **[Submission Notebook](https://www.kaggle.com/code/andrewjdarley/submission-notebook)**: Running inference and generating submission files \n\n## About this Notebook\n\nThis training notebook implements a full YOLOv8 training pipeline for detecting bacterial flagellar motors in tomographic slices. The notebook:\n\n1. **Dataset Configuration**: Sets up and validates the YOLO-format dataset YAML configuration\n2. **Model Initialization**: Loads pre-trained YOLOv8 weights for transfer learning\n3. **Training Process**: Fine tunes the model with early stopping and periodic checkpoints\n4. **Loss Visualization**: Plots training and validation dfl loss curves to monitor progress\n5. **Performance Evaluation**: Tests the trained model on random validation samples\n6. **Model Export**: Saves the trained weights for use in the submission notebook","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# !python -m build --wheel --no-isolation\n# !pip install --upgrade build wheel setuptools","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 方法 A：直接指定文件路径\n#!pip install /kaggle/input/ultralytics-thop/ultralytics_thop-2.0.14-py3-none-any.whl --force-reinstall --no-index --no-deps\n!pip install /kaggle/input/ultralytics-timm/ultralytics-8.3.133-py3-none-any.whl --no-deps","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T20:37:45.574402Z","iopub.execute_input":"2025-05-28T20:37:45.574748Z","iopub.status.idle":"2025-05-28T20:37:48.124129Z","shell.execute_reply.started":"2025-05-28T20:37:45.574713Z","shell.execute_reply":"2025-05-28T20:37:48.122868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install /kaggle/input/yolo-plus/ultralytics-8.3.133-py3-none-any.whl --no-deps","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T21:41:14.055972Z","iopub.execute_input":"2025-05-28T21:41:14.056325Z","iopub.status.idle":"2025-05-28T21:41:15.799699Z","shell.execute_reply.started":"2025-05-28T21:41:14.056294Z","shell.execute_reply":"2025-05-28T21:41:15.798732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport timm\n\nmodel = timm.create_model('resnet50', pretrained=False)\nmodel.eval()\nx = torch.randn(1, 3, 256, 256)\n\ndef save_hook(name):\n    def fn(module, input, output):\n        print(f\"{name}: {output.shape}\")\n    return fn\n\nhandles = []\nfor i in range(1, 5):  # layer1~layer4\n    layer = getattr(model, f'layer{i}')\n    handles.append(layer.register_forward_hook(save_hook(f'layer{i}')))\n\nwith torch.no_grad():\n    _ = model(x)\n\nfor h in handles:\n    h.remove()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T20:38:11.041031Z","iopub.execute_input":"2025-05-28T20:38:11.041418Z","iopub.status.idle":"2025-05-28T20:38:21.616292Z","shell.execute_reply.started":"2025-05-28T20:38:11.041385Z","shell.execute_reply":"2025-05-28T20:38:21.615215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport timm\n\nmodel = timm.create_model('convnext_tiny', features_only=True, pretrained=True)\nmodel.eval()\nx = torch.randn(1, 3, 256, 256)\n\nwith torch.no_grad():\n    feats = model(x)\n    for i, f in enumerate(feats):\n        print(f\"stage{i}: {f.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T20:38:23.206551Z","iopub.execute_input":"2025-05-28T20:38:23.206822Z","iopub.status.idle":"2025-05-28T20:38:23.918265Z","shell.execute_reply.started":"2025-05-28T20:38:23.206800Z","shell.execute_reply":"2025-05-28T20:38:23.917376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport timm\n\nimport torch\nimport timm\n\nmodel = timm.create_model('swinv2_tiny_window8_256', pretrained=False)\nmodel.eval()\nx = torch.randn(1, 3, 256, 256)\n\ndef save_hook(name):\n    def fn(module, input, output):\n        print(f\"{name}: {output.shape}\")\n    return fn\n\nhandles = []\n# Swin V2 的主干是 model.layers[0], model.layers[1], model.layers[2], model.layers[3]\nfor i in range(4):\n    handles.append(model.layers[i].register_forward_hook(save_hook(f'layers[{i}]')))\n\nwith torch.no_grad():\n    _ = model(x)\n\nfor h in handles:\n    h.remove()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T20:38:23.919485Z","iopub.execute_input":"2025-05-28T20:38:23.919839Z","iopub.status.idle":"2025-05-28T20:38:24.622444Z","shell.execute_reply.started":"2025-05-28T20:38:23.919806Z","shell.execute_reply":"2025-05-28T20:38:24.621535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport timm\n\nmodel = timm.create_model('efficientnet_b5', pretrained=False)\nmodel.eval()\nx = torch.randn(1, 3, 256, 256)\n\n# 用 hook 方式输出每个 block 的 shape\ndef save_hook(name):\n    def fn(module, input, output):\n        print(f\"{name}: {output.shape}\")\n    return fn\n\nhandles = []\nfor i, block in enumerate(model.blocks):\n    handles.append(block.register_forward_hook(save_hook(f\"Block {i}\")))\n\n# 正确做法：直接把 x 输入整个 model\nwith torch.no_grad():\n    _ = model(x)\n\nfor h in handles:\n    h.remove()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T20:43:00.968405Z","iopub.execute_input":"2025-05-28T20:43:00.968751Z","iopub.status.idle":"2025-05-28T20:43:01.660515Z","shell.execute_reply.started":"2025-05-28T20:43:00.968723Z","shell.execute_reply":"2025-05-28T20:43:01.659549Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport timm\n\nmodel = timm.create_model('efficientnet_b2', pretrained=False)\nmodel.eval()\nx = torch.randn(1, 3, 256, 256)\n\n# 用 hook 方式输出每个 block 的 shape\ndef save_hook(name):\n    def fn(module, input, output):\n        print(f\"{name}: {output.shape}\")\n    return fn\n\nhandles = []\nfor i, block in enumerate(model.blocks):\n    handles.append(block.register_forward_hook(save_hook(f\"Block {i}\")))\n\n# 正确做法：直接把 x 输入整个 model\nwith torch.no_grad():\n    _ = model(x)\n\nfor h in handles:\n    h.remove()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T20:47:36.353503Z","iopub.execute_input":"2025-05-28T20:47:36.353872Z","iopub.status.idle":"2025-05-28T20:47:36.621713Z","shell.execute_reply.started":"2025-05-28T20:47:36.353841Z","shell.execute_reply":"2025-05-28T20:47:36.620584Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# 2. 然后正常 import 并构建  \nfrom ultralytics import YOLO\n# 1. 你的 YAML 配置字符串\n# import timm.layers.patch_embed as _pe\n# _pe._assert = lambda cond, msg=None: None\nswin_yolo_config = \"\"\"\nnc: 80 # number of classes\nbackbone:\n  - [-1, 1, Timm, [512, 'efficientnet_b5', True, True, 0, True]]\n  - [0, 1, Index, [64, 2]]    # features[2]  [1, 64, 32, 32]\n  - [0, 1, Index, [176, 3]]   # features[4]  [1, 176, 16, 16]\n  - [0, 1, Index, [512, 4]]   # features[6]  [1, 512, 8, 8]\n  - [-1, 1, SPPF, [512, 5]]\n\nhead:\n  # 上采样/拼接/检测头，通道数建议与 backbone 输出保持一致\n  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]            # 5, SPPF上采样 (8->16)\n  - [[-1, 2], 1, Concat, [1]]                             # 6, 拼接16x16的两个特征\n  - [-1, 3, C2f, [176]]                                   # 7, 通道数和P4对齐\n\n  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]            # 8, 上采样 (16->32)\n  - [[-1, 1], 1, Concat, [1]]                             # 9, 拼接32x32的两个特征\n  - [-1, 3, C2f, [64]]                                    # 10, 通道数和P3对齐\n\n  - [-1, 1, Conv, [64, 3, 2]]                             # 11, 下采样 (32->16)\n  - [[-1, 7], 1, Concat, [1]]                             # 12, 拼接16x16的两个特征\n  - [-1, 3, C2f, [176]]                                   # 13\n\n  - [-1, 1, Conv, [176, 3, 2]]                            # 14, 下采样 (16->8)\n  - [[-1, 4], 1, Concat, [1]]                             # 15, 拼接8x8的两个特征\n  - [-1, 3, C2f, [512]]                                   # 16\n\n  - [[10, 13, 16], 1, Detect, [nc]]                       # 17, 检测头, 多尺度\n\n\"\"\"\n\nswin_yolo_config = \"\"\"\nnc: 80 # number of classes\nbackbone:\n  - [-1, 1, Timm, [352, 'efficientnet_b2', True, True, 0, True]]\n  - [0, 1, Index, [48, 2]]    # features[2]  [1, 64, 32, 32]\n  - [0, 1, Index, [120, 3]]   # features[4]  [1, 176, 16, 16]\n  - [0, 1, Index, [352, 4]]   # features[6]  [1, 512, 8, 8]\n  - [-1, 1, SPPF, [352, 5]]\n\nhead:\n  # 上采样/拼接/检测头，通道数建议与 backbone 输出保持一致\n  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]            # 5, SPPF上采样 (8->16)\n  - [[-1, 2], 1, Concat, [1]]                             # 6, 拼接16x16的两个特征\n  - [-1, 3, C2f, [120]]                                   # 7, 通道数和P4对齐\n\n  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]            # 8, 上采样 (16->32)\n  - [[-1, 1], 1, Concat, [1]]                             # 9, 拼接32x32的两个特征\n  - [-1, 3, C2f, [48]]                                    # 10, 通道数和P3对齐\n\n  - [-1, 1, Conv, [64, 3, 2]]                             # 11, 下采样 (32->16)\n  - [[-1, 7], 1, Concat, [1]]                             # 12, 拼接16x16的两个特征\n  - [-1, 3, C2f, [120]]                                   # 13\n\n  - [-1, 1, Conv, [176, 3, 2]]                            # 14, 下采样 (16->8)\n  - [[-1, 4], 1, Concat, [1]]                             # 15, 拼接8x8的两个特征\n  - [-1, 3, C2f, [352]]                                   # 16\n\n  - [[10, 13, 16], 1, Detect, [nc]]                       # 17, 检测头, 多尺度\n\n\"\"\"\n\n\n# 2. 写入到本地文件\nyaml_path= \"swin_yolo.yaml\"\nwith open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n    f.write(swin_yolo_config)\n\n# 3. 直接用文件路径加载模型结构\nmodel = YOLO(yaml_path,verbose=False)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T20:50:38.858493Z","iopub.execute_input":"2025-05-28T20:50:38.858834Z","iopub.status.idle":"2025-05-28T20:50:39.415212Z","shell.execute_reply.started":"2025-05-28T20:50:38.858811Z","shell.execute_reply":"2025-05-28T20:50:39.414092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom ultralytics import YOLO\nswin_yolo_config = \"\"\"\n# Parameters\nnc: 80  # number of classes\nscales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'\n  # [depth, width, max_channels]\n  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs\n  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs\n  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs\n  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs\n\n# YOLOv8.0n backbone\nbackbone:\n  # [from, repeats, module, args]\n  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2\n  - [-1, 1, Conv, [128, 3, 1]]  # 1\n  - [-1, 1, space_to_depth,[1]] # 2-P2/4\n  - [-1, 3, C2f, [128, True]]\n  - [-1, 1, Conv, [256, 3, 1]]  # 4\n  - [-1, 1, space_to_depth,[1]] # 5-P3/8\n  - [-1, 6, C2f, [256, True]]\n  - [-1, 1, Conv, [512, 3, 1]]  # 7\n  - [-1, 1, space_to_depth,[1]] # 8-P4/16\n  - [-1, 6, C2f, [512, True]]\n  - [-1, 1, Conv, [1024, 3, 1]]  # 10\n  - [-1, 1, space_to_depth,[1]] # 11-P5/32\n  - [-1, 3, C2f, [1024, True]]\n  - [-1, 1, SPPF, [1024, 5]]  # 13\n\n# YOLOv8.0n head\nhead:\n  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n  - [[-1, 9], 1, Concat, [1]]  # cat backbone P4\n  - [-1, 3, C2f, [512]]  # 16\n\n  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n  - [[-1, 6], 1, Concat, [1]]  # cat backbone P3\n  - [-1, 3, C2f, [256]]  # 19 (P3/8-small)\n\n  - [-1, 1, Conv, [256, 3, 2]]\n  - [[-1, 16], 1, Concat, [1]]  # cat head P4\n  - [-1, 3, C2f, [512]]  # 22 (P4/16-medium)\n\n  - [-1, 1, Conv, [512, 3, 2]]\n  - [[-1, 13], 1, Concat, [1]]  # cat head P5\n  - [-1, 3, C2f, [1024]]  # 25 (P5/32-large)\n\n  - [[19, 22, 25], 1, Detect, [nc]]  # Detect(P3, P4, P5)\n\n\n\"\"\"\n\nyaml_path= \"swin_yolo.yaml\"\nwith open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n    f.write(swin_yolo_config)\n\n# 3. 直接用文件路径加载模型结构\nmodel = YOLO(yaml_path,verbose=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T21:41:23.657040Z","iopub.execute_input":"2025-05-28T21:41:23.657377Z","iopub.status.idle":"2025-05-28T21:41:27.652555Z","shell.execute_reply.started":"2025-05-28T21:41:23.657352Z","shell.execute_reply":"2025-05-28T21:41:27.651857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nswin_yolo_config = \"\"\"\nnc: 10  # number of classes\ndepth_multiple: 0.33  # scales module repeats\nwidth_multiple: 1.00  # scales convolution channels\n\n# YOLOv8.0n backbone\nbackbone:\n  # [from, repeats, module, args]\n  - [-1, 1, Conv, [16, 3, 2]]  # 0-P1/2\n  - [-1, 1, Conv, [32, 3, 2]]  # 1-P2/4\n  - [-1, 3, C2f, [32, True]]\n  - [-1, 1, Conv, [64, 3, 2]]  # 3-P3/8\n  - [-1, 6, C2f, [64, True]]\n  - [-1, 1, Conv, [128, 3, 2]]  # 5-P4/16\n  - [-1, 6, C2f, [128, True]]\n  - [-1, 1, Conv, [256, 3, 2]]  # 7-P5/32\n  - [-1, 3, C2f, [256, True]]\n  - [-1, 1, SPPF, [256, 5]]  # 9\n\n# YOLOv8.0n head\nhead:\n  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4\n  - [-1, 3, C2f, [128]]  # 12\n\n  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3\n  - [-1, 3, C2f, [64]]  # 15 (P3/8-small)\n\n  - [[15], 1, DyDetect, [nc]]  # Detect(P3, P4, P5)\n\n\"\"\"\n\n# yaml_path= \"swin_yolo.yaml\"\n# with open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n#     f.write(swin_yolo_config)\n\n# # 3. 直接用文件路径加载模型结构\n# model = YOLO(yaml_path,verbose=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T21:53:27.158496Z","iopub.execute_input":"2025-05-28T21:53:27.158946Z","iopub.status.idle":"2025-05-28T21:53:27.164303Z","shell.execute_reply.started":"2025-05-28T21:53:27.158902Z","shell.execute_reply":"2025-05-28T21:53:27.163496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def ensure_channels_first(x):\n    # x: [B, H, W, C] or [B, C, H, W]\n    if x.dim() == 4 and x.shape[1] < 10 and x.shape[-1] > 10:\n        return x.permute(0, 3, 1, 2).contiguous()\n    return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T20:15:23.541335Z","iopub.execute_input":"2025-05-28T20:15:23.541701Z","iopub.status.idle":"2025-05-28T20:15:23.545225Z","shell.execute_reply.started":"2025-05-28T20:15:23.541672Z","shell.execute_reply":"2025-05-28T20:15:23.544540Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = YOLO(yaml_path,verbose=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T20:15:48.601373Z","iopub.execute_input":"2025-05-28T20:15:48.601712Z","iopub.status.idle":"2025-05-28T20:15:49.559768Z","shell.execute_reply.started":"2025-05-28T20:15:48.601685Z","shell.execute_reply":"2025-05-28T20:15:49.559062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport os\nimport torch\nimport numpy as np\nimport random\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\n# from ultralytics import YOLO\nimport yaml\nimport pandas as pd\nimport json\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\nrandom.seed(42)\ntorch.manual_seed(42)\n\n# Define paths for Kaggle environment\nyolo_dataset_dir = \"/kaggle/input/parse-data/yolo_dataset\"\nyolo_weights_dir = \"/kaggle/working/yolo_weights\"\nyolo_pretrained_weights = \"/kaggle/input/yolo11/pytorch/default/1/yolo11n.pt\"  # Path to pre-downloaded weights\n\n# Create weights directory if it doesn't exist\nos.makedirs(yolo_weights_dir, exist_ok=True)\n\ndef fix_yaml_paths(yaml_path):\n    \"\"\"\n    Fix the paths in the YAML file to match the actual Kaggle directories\n    \n    Args:\n        yaml_path (str): Path to the original dataset YAML file\n        \n    Returns:\n        str: Path to the fixed YAML file\n    \"\"\"\n    print(f\"Fixing YAML paths in {yaml_path}\")\n    \n    # Read the original YAML\n    with open(yaml_path, 'r') as f:\n        yaml_data = yaml.safe_load(f)\n    \n    # Update paths to use actual dataset location\n    if 'path' in yaml_data:\n        yaml_data['path'] = yolo_dataset_dir\n    \n    # Create a new fixed YAML in the working directory\n    fixed_yaml_path = \"/kaggle/working/fixed_dataset.yaml\"\n    with open(fixed_yaml_path, 'w') as f:\n        yaml.dump(yaml_data, f)\n    \n    print(f\"Created fixed YAML at {fixed_yaml_path} with path: {yaml_data.get('path')}\")\n    return fixed_yaml_path\n\ndef plot_dfl_loss_curve(run_dir):\n    \"\"\"\n    Plot the DFL loss curves for train and validation, marking the best model\n    \n    Args:\n        run_dir (str): Directory where the training results are stored\n    \"\"\"\n    # Path to the results CSV file\n    results_csv = os.path.join(run_dir, 'results.csv')\n    \n    if not os.path.exists(results_csv):\n        print(f\"Results file not found at {results_csv}\")\n        return\n    \n    # Read results CSV\n    results_df = pd.read_csv(results_csv)\n    \n    # Check if DFL loss columns exist\n    train_dfl_col = [col for col in results_df.columns if 'train/dfl_loss' in col]\n    val_dfl_col = [col for col in results_df.columns if 'val/dfl_loss' in col]\n    \n    if not train_dfl_col or not val_dfl_col:\n        print(\"DFL loss columns not found in results CSV\")\n        print(f\"Available columns: {results_df.columns.tolist()}\")\n        return\n    \n    train_dfl_col = train_dfl_col[0]\n    val_dfl_col = val_dfl_col[0]\n    \n    # Find the epoch with the best validation loss\n    best_epoch = results_df[val_dfl_col].idxmin()\n    best_val_loss = results_df.loc[best_epoch, val_dfl_col]\n    \n    # Create the plot\n    plt.figure(figsize=(10, 6))\n    \n    # Plot training and validation losses\n    plt.plot(results_df['epoch'], results_df[train_dfl_col], label='Train DFL Loss')\n    plt.plot(results_df['epoch'], results_df[val_dfl_col], label='Validation DFL Loss')\n    \n    # Mark the best model with a vertical line\n    plt.axvline(x=results_df.loc[best_epoch, 'epoch'], color='r', linestyle='--', \n                label=f'Best Model (Epoch {int(results_df.loc[best_epoch, \"epoch\"])}, Val Loss: {best_val_loss:.4f})')\n    \n    # Add labels and legend\n    plt.xlabel('Epoch')\n    plt.ylabel('DFL Loss')\n    plt.title('Training and Validation DFL Loss')\n    plt.legend()\n    plt.grid(True, linestyle='--', alpha=0.7)\n    \n    # Save the plot in the same directory as weights\n    plot_path = os.path.join(run_dir, 'dfl_loss_curve.png')\n    plt.savefig(plot_path)\n    \n    # Also save it to the working directory for easier access\n    plt.savefig(os.path.join('/kaggle/working', 'dfl_loss_curve.png'))\n    \n    print(f\"Loss curve saved to {plot_path}\")\n    plt.close()\n    \n    # Return the best epoch info\n    return best_epoch, best_val_loss\n\ndef train_yolo_model(yaml_path, pretrained_weights_path, epochs=30, batch_size=4, img_size=640):\n    \"\"\"\n    Train a YOLO model on the prepared dataset\n    \n    Args:\n        yaml_path (str): Path to the dataset YAML file\n        pretrained_weights_path (str): Path to pre-downloaded weights file\n        epochs (int): Number of training epochs\n        batch_size (int): Batch size for training\n        img_size (int): Image size for training\n    \"\"\"\n    print(f\"Loading pre-trained weights from: {pretrained_weights_path}\")\n    \n    # Load a pre-trained YOLOv8 model\n    #model = YOLO(pretrained_weights_path)\n    model = YOLO(\"swin_yolo.yaml\")\n    # Train the model with early stopping\n    results = model.train(\n        data=yaml_path,\n        epochs=epochs,\n        batch=batch_size,\n        imgsz=img_size,\n        project=yolo_weights_dir,\n        name='motor_detector',\n        exist_ok=True,\n        patience=5,              # Early stopping if no improvement for 5 epochs\n        save_period=5,           # Save checkpoints every 5 epochs\n        val=True,                # Ensure validation is performed\n        verbose=True             # Show detailed output during training\n    )\n    \n    # Get the path to the run directory\n    run_dir = os.path.join(yolo_weights_dir, 'motor_detector')\n    \n    # Plot and save the loss curve\n    best_epoch_info = plot_dfl_loss_curve(run_dir)\n    \n    if best_epoch_info:\n        best_epoch, best_val_loss = best_epoch_info\n        print(f\"\\nBest model found at epoch {best_epoch} with validation DFL loss: {best_val_loss:.4f}\")\n    \n    return model, results\n\ndef predict_on_samples(model, num_samples=4):\n    \"\"\"\n    Run predictions on random validation samples and display results\n    \n    Args:\n        model: Trained YOLO model\n        num_samples (int): Number of random samples to test\n    \"\"\"\n    # Get validation images\n    val_dir = os.path.join(yolo_dataset_dir, 'images', 'val')\n    if not os.path.exists(val_dir):\n        print(f\"Validation directory not found at {val_dir}\")\n        # Try train directory instead if val doesn't exist\n        val_dir = os.path.join(yolo_dataset_dir, 'images', 'train')\n        print(f\"Using train directory for predictions instead: {val_dir}\")\n        \n    if not os.path.exists(val_dir):\n        print(\"No images directory found for predictions\")\n        return\n    \n    val_images = os.listdir(val_dir)\n    \n    if len(val_images) == 0:\n        print(\"No images found for prediction\")\n        return\n    \n    # Select random samples\n    num_samples = min(num_samples, len(val_images))\n    samples = random.sample(val_images, num_samples)\n    \n    # Create figure\n    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n    axes = axes.flatten()\n    \n    for i, img_file in enumerate(samples):\n        if i >= len(axes):\n            break\n            \n        img_path = os.path.join(val_dir, img_file)\n        \n        # Run prediction\n        results = model.predict(img_path, conf=0.25)[0]\n        \n        # Load and display the image\n        img = Image.open(img_path)\n        axes[i].imshow(np.array(img), cmap='gray')\n        \n        # Draw ground truth box if available (from filename)\n        try:\n            # This assumes your filenames contain coordinates in a specific format\n            parts = img_file.split('_')\n            y_part = [p for p in parts if p.startswith('y')]\n            x_part = [p for p in parts if p.startswith('x')]\n            \n            if y_part and x_part:\n                y_gt = int(y_part[0][1:])\n                x_gt = int(x_part[0][1:].split('.')[0])\n                \n                box_size = 24\n                rect_gt = Rectangle((x_gt - box_size//2, y_gt - box_size//2), \n                              box_size, box_size, \n                              linewidth=1, edgecolor='g', facecolor='none')\n                axes[i].add_patch(rect_gt)\n        except:\n            pass  # Skip ground truth if parsing fails\n        \n        # Draw predicted boxes (red)\n        if len(results.boxes) > 0:\n            boxes = results.boxes.xyxy.cpu().numpy()\n            confs = results.boxes.conf.cpu().numpy()\n            \n            for box, conf in zip(boxes, confs):\n                x1, y1, x2, y2 = box\n                rect_pred = Rectangle((x1, y1), x2-x1, y2-y1, \n                                     linewidth=1, edgecolor='r', facecolor='none')\n                axes[i].add_patch(rect_pred)\n                axes[i].text(x1, y1-5, f'{conf:.2f}', color='red')\n        \n        axes[i].set_title(f\"Image: {img_file}\\nGround Truth (green) vs Prediction (red)\")\n    \n    plt.tight_layout()\n    \n    # Save the predictions plot\n    plt.savefig(os.path.join('/kaggle/working', 'predictions.png'))\n    plt.show()\n\n# Check and create a dataset YAML if needed\ndef prepare_dataset():\n    \"\"\"\n    Check if dataset exists and create a proper YAML if needed\n    \n    Returns:\n        str: Path to the YAML file to use for training\n    \"\"\"\n    # Check if images exist\n    train_images_dir = os.path.join(yolo_dataset_dir, 'images', 'train')\n    val_images_dir = os.path.join(yolo_dataset_dir, 'images', 'val')\n    train_labels_dir = os.path.join(yolo_dataset_dir, 'labels', 'train')\n    val_labels_dir = os.path.join(yolo_dataset_dir, 'labels', 'val')\n    \n    # Print directory existence status\n    print(f\"Directory status:\")\n    print(f\"- Train images dir exists: {os.path.exists(train_images_dir)}\")\n    print(f\"- Val images dir exists: {os.path.exists(val_images_dir)}\")\n    print(f\"- Train labels dir exists: {os.path.exists(train_labels_dir)}\")\n    print(f\"- Val labels dir exists: {os.path.exists(val_labels_dir)}\")\n    \n    # Check for original YAML file\n    original_yaml_path = os.path.join(yolo_dataset_dir, 'dataset.yaml')\n    \n    if os.path.exists(original_yaml_path):\n        print(f\"Found original dataset.yaml at {original_yaml_path}\")\n        # Fix the paths in the YAML\n        return fix_yaml_paths(original_yaml_path)\n    else:\n        print(f\"Original dataset.yaml not found, creating a new one\")\n        \n        # Create a new YAML file\n        yaml_data = {\n            'path': yolo_dataset_dir,\n            'train': 'images/train',\n            'val': 'images/train' if not os.path.exists(val_images_dir) else 'images/val',\n            'names': {0: 'motor'}\n        }\n        \n        new_yaml_path = \"/kaggle/working/dataset.yaml\"\n        with open(new_yaml_path, 'w') as f:\n            yaml.dump(yaml_data, f)\n            \n        print(f\"Created new YAML at {new_yaml_path}\")\n        return new_yaml_path\n\n# Main execution\ndef main():\n    print(\"Starting YOLO training process...\")\n    \n    # Prepare dataset and get YAML path\n    yaml_path = prepare_dataset()\n    print(f\"Using YAML file: {yaml_path}\")\n    \n    # Print YAML file contents\n    with open(yaml_path, 'r') as f:\n        yaml_content = f.read()\n    print(f\"YAML file contents:\\n{yaml_content}\")\n    \n    # Train model\n    print(\"\\nStarting YOLO training...\")\n    model, results = train_yolo_model(\n        yaml_path,\n        pretrained_weights_path=yolo_pretrained_weights,\n        epochs=30  # Using 30 epochs instead of 100 for faster training\n    )\n    \n    print(\"\\nTraining complete!\")\n    \n    # Run predictions\n    print(\"\\nRunning predictions on sample images...\")\n    predict_on_samples(model, num_samples=4)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T20:39:38.344118Z","iopub.execute_input":"2025-05-28T20:39:38.344483Z","iopub.status.idle":"2025-05-28T20:40:30.513159Z","shell.execute_reply.started":"2025-05-28T20:39:38.344454Z","shell.execute_reply":"2025-05-28T20:40:30.511570Z"}},"outputs":[],"execution_count":null}]}