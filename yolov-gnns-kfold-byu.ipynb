{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #6cb4e4;  text-align: center;  padding: 0.25em;  border-top: solid 2.5px #6cb4e4;  border-bottom: solid 2.5px #6cb4e4;  background: -webkit-repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);  background: repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);height:45px;\">\n",
    "<b>\n",
    "Only Submission(LoadLocalTrainModel)\n",
    "</b></h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #6cb4e4;  text-align: center;  padding: 0.25em;  border-top: solid 2.5px #6cb4e4;  border-bottom: solid 2.5px #6cb4e4;  background: -webkit-repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);  background: repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);height:45px;\">\n",
    "<b>\n",
    "Inference Pipeline\n",
    "</b></h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **》》》 [IMPORTANT] Env Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:51:00.734973Z",
     "iopub.status.busy": "2025-06-03T10:51:00.734533Z",
     "iopub.status.idle": "2025-06-03T10:51:00.740874Z",
     "shell.execute_reply": "2025-06-03T10:51:00.739695Z",
     "shell.execute_reply.started": "2025-06-03T10:51:00.734932Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Train Model \"\"\"\n",
    "model_path = \"/kaggle/input/yolo11n-byu/yolo/yolo11x_fold1.pt\"\n",
    "\n",
    "\"\"\" [IMPORTANT]\n",
    "* This parameter has a significant impact on the value of LB since it is the threshold for the prediction score inferred by the model.\n",
    "* In my experiments, 0.5 to 0.55 is optimal for local CV, but when submitting, 0.35 to 0.45 seems to give better results, so there is a difference.\n",
    "\"\"\"\n",
    "YOLO_THR = 0.05\n",
    "GNN_THR = 0.05\n",
    "\n",
    "MAX_DETECTIONS_PER_TOMO = 3\n",
    "NMS_IOU_THRESHOLD = 0.2\n",
    "CONCENTRATION = 1\n",
    "BATCH_SIZE = 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:51:00.74241Z",
     "iopub.status.busy": "2025-06-03T10:51:00.742098Z",
     "iopub.status.idle": "2025-06-03T10:51:00.759566Z",
     "shell.execute_reply": "2025-06-03T10:51:00.758802Z",
     "shell.execute_reply.started": "2025-06-03T10:51:00.742378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "knn_folds = [\n",
    "    '/kaggle/input/yolo11x-byu/checkpoint/knn_graph_12_8_4.pth',\n",
    "    '/kaggle/input/yolo11x-byu/checkpoint/knn_graph_12_8_3.pth',\n",
    "    '/kaggle/input/yolo11x-byu/checkpoint/knn_graph_12_8_2.pth',\n",
    "    '/kaggle/input/yolo11x-byu/checkpoint/knn_graph_12_8_1.pth',\n",
    "    '/kaggle/input/yolo11x-byu/checkpoint/knn_graph_12_8_0.pth'\n",
    "]\n",
    "\n",
    "delaunay_folds = [\n",
    "    '/kaggle/input/yolo11x-byu/checkpoint/delaunay_graph_15_8_4.pth',\n",
    "    '/kaggle/input/yolo11x-byu/checkpoint/delaunay_graph_15_8_3.pth',\n",
    "    '/kaggle/input/yolo11x-byu/checkpoint/delaunay_graph_15_8_2.pth',\n",
    "    '/kaggle/input/yolo11x-byu/checkpoint/delaunay_graph_15_8_1.pth',\n",
    "    '/kaggle/input/yolo11x-byu/checkpoint/delaunay_graph_15_8_0.pth'\n",
    "]\n",
    "\n",
    "knn_conf = [0.1, 0.1, 0.4, 0.4, 0.4]\n",
    "delaunay_conf = [0.4] * (len(delaunay_folds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **》》》 Ultralytics Offline Install**(v8.3.88[2025/03/11 ReleaseVersion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-03T10:51:00.761836Z",
     "iopub.status.busy": "2025-06-03T10:51:00.761527Z",
     "iopub.status.idle": "2025-06-03T10:51:20.549485Z",
     "shell.execute_reply": "2025-06-03T10:51:20.548673Z",
     "shell.execute_reply.started": "2025-06-03T10:51:00.761808Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install /kaggle/input/pip-install-pyg/torch_spline_conv-1.2.2+pt25cu124-cp310-cp310-linux_x86_64.whl\n",
    "!pip install /kaggle/input/pip-install-pyg/torch_sparse-0.6.18+pt25cu124-cp310-cp310-linux_x86_64.whl\n",
    "!pip install /kaggle/input/pip-install-pyg/pyg_lib-0.4.0+pt25cu124-cp310-cp310-linux_x86_64.whl\n",
    "!pip install /kaggle/input/pip-install-pyg/torch_cluster-1.6.3+pt25cu124-cp310-cp310-linux_x86_64.whl\n",
    "!pip install /kaggle/input/pip-install-pyg/torch_geometric-2.6.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-06-03T10:51:20.551176Z",
     "iopub.status.busy": "2025-06-03T10:51:20.55093Z",
     "iopub.status.idle": "2025-06-03T10:52:18.201534Z",
     "shell.execute_reply": "2025-06-03T10:52:18.200186Z",
     "shell.execute_reply.started": "2025-06-03T10:51:20.551154Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"[INFO]\n",
    "* This notebookinstall Ultralytics v8.3.88(2025/03/11 ReleaseVersion)\n",
    "  Can use YOLO12 is latest family version. \n",
    "* If you need a newer version, you can make it available by running and attaching the notebook.\n",
    "  https://www.kaggle.com/code/hideyukizushi/ultralytics-offlineinstall-yolo12-weights\n",
    "\"\"\"\n",
    "!tar xfvz /kaggle/input/ultralytics-offlineinstall-yolo12-weights/archive.tar.gz\n",
    "!pip install --no-index --find-links=./packages ultralytics\n",
    "!rm -rf ./packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **》》》 Import Libs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:18.203188Z",
     "iopub.status.busy": "2025-06-03T10:52:18.202863Z",
     "iopub.status.idle": "2025-06-03T10:52:23.609752Z",
     "shell.execute_reply": "2025-06-03T10:52:23.608842Z",
     "shell.execute_reply.started": "2025-06-03T10:52:18.203156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "from ultralytics import YOLO\n",
    "import threading\n",
    "import time\n",
    "from contextlib import nullcontext\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import sys\n",
    "import gc\n",
    "sys.path.append('/kaggle/input/yolo-gnn-refine-byu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:23.611196Z",
     "iopub.status.busy": "2025-06-03T10:52:23.610609Z",
     "iopub.status.idle": "2025-06-03T10:52:28.377833Z",
     "shell.execute_reply": "2025-06-03T10:52:28.377141Z",
     "shell.execute_reply.started": "2025-06-03T10:52:23.611147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn.models import GraphSAGE, GAT, CorrectAndSmooth\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch_geometric.nn import LayerNorm\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import dropout_edge\n",
    "from torch.distributions import Beta\n",
    "import torchvision.transforms as transforms\n",
    "from torch_geometric.nn.conv import TransformerConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_cluster import knn_graph\n",
    "from torch_geometric.nn import radius_graph\n",
    "from torch_geometric.transforms import AddRandomWalkPE\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **》》》 Seed Fix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:28.379297Z",
     "iopub.status.busy": "2025-06-03T10:52:28.378607Z",
     "iopub.status.idle": "2025-06-03T10:52:28.389637Z",
     "shell.execute_reply": "2025-06-03T10:52:28.389037Z",
     "shell.execute_reply.started": "2025-06-03T10:52:28.379263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:28.390893Z",
     "iopub.status.busy": "2025-06-03T10:52:28.390564Z",
     "iopub.status.idle": "2025-06-03T10:52:28.406308Z",
     "shell.execute_reply": "2025-06-03T10:52:28.405485Z",
     "shell.execute_reply.started": "2025-06-03T10:52:28.390862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/\"\n",
    "test_dir = os.path.join(data_path, \"test\")\n",
    "submission_path = \"/kaggle/working/submission.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **》》》 GNN Refinement Tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:28.409494Z",
     "iopub.status.busy": "2025-06-03T10:52:28.409297Z",
     "iopub.status.idle": "2025-06-03T10:52:28.421083Z",
     "shell.execute_reply": "2025-06-03T10:52:28.420455Z",
     "shell.execute_reply.started": "2025-06-03T10:52:28.409477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DATA_CONFIG:\n",
    "    radius = 30\n",
    "    num_samples = 20\n",
    "    thr = 10\n",
    "    thr_sim = 0.25\n",
    "    k = 15\n",
    "    w = [0.5, 0.5]\n",
    "\n",
    "\n",
    "class TRAIN_CONFIG:\n",
    "    epochs = 200\n",
    "    patience = 10\n",
    "    batch_size = 8\n",
    "    lr = 5e-4\n",
    "    weight_decay = 0\n",
    "    ckpt_epoch_freq = 1\n",
    "\n",
    "\n",
    "class MODEL_CONIFG_1:\n",
    "    num_layers = 8\n",
    "    hidden_channels = 256\n",
    "    pos_weight = 8\n",
    "    jk = 'lstm'\n",
    "    dropout = 0.3\n",
    "    conf = 0.1\n",
    "    graph_augment = False\n",
    "    use_pe = True\n",
    "    walk_length = 8\n",
    "    weight_path = '/kaggle/input/yolo-gnn-refine-byu/checkpoint/knn_graph_15_8_4.pth'\n",
    "\n",
    "class MODEL_CONIFG_2:\n",
    "    num_layers = 8\n",
    "    hidden_channels = 256\n",
    "    pos_weight = 8\n",
    "    jk = 'lstm'\n",
    "    dropout = 0.3\n",
    "    conf = 0.1\n",
    "    graph_augment = False\n",
    "    use_pe = True\n",
    "    walk_length = 8\n",
    "    weight_path = '/kaggle/input/yolo-gnn-refine-byu/checkpoint/delaunay_graph_15_8_4.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:28.42241Z",
     "iopub.status.busy": "2025-06-03T10:52:28.422182Z",
     "iopub.status.idle": "2025-06-03T10:52:28.439278Z",
     "shell.execute_reply": "2025-06-03T10:52:28.438565Z",
     "shell.execute_reply.started": "2025-06-03T10:52:28.422391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_feature_map(model):\n",
    "    features = {}\n",
    "    def make_hook(name):\n",
    "        def hook(module, input, output):\n",
    "            features[name] = output\n",
    "        return hook\n",
    "    model.model.model[16].register_forward_hook(make_hook(\"bifpn\"))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:28.440212Z",
     "iopub.status.busy": "2025-06-03T10:52:28.439965Z",
     "iopub.status.idle": "2025-06-03T10:52:28.454456Z",
     "shell.execute_reply": "2025-06-03T10:52:28.453758Z",
     "shell.execute_reply.started": "2025-06-03T10:52:28.440192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def delaunay_graph(x):\n",
    "    points = x.cpu().numpy()  # assuming x is a tensor of shape [num_points, dims]\n",
    "    tri = Delaunay(points)\n",
    "    edges = set()\n",
    "\n",
    "    for simplex in tri.simplices:\n",
    "        for i in range(len(simplex)):\n",
    "            for j in range(i + 1, len(simplex)):\n",
    "                edges.add(tuple(sorted((simplex[i], simplex[j]))))\n",
    "\n",
    "    edge_index = torch.tensor(list(edges), dtype=torch.long).t()\n",
    "    return edge_index\n",
    "\n",
    "def mst_graph(x):\n",
    "    pos_np = x.numpy()\n",
    "    dist_matrix = squareform(pdist(pos_np))  # pairwise distances\n",
    "    mst = minimum_spanning_tree(dist_matrix)  # sparse MST\n",
    "    row, col = mst.nonzero()\n",
    "    edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "    return edge_index\n",
    "\n",
    "\n",
    "def kdtree_graph(x, k):\n",
    "    N = x.shape[0]\n",
    "    pos_np = x.numpy()\n",
    "    tree = KDTree(pos_np)\n",
    "    ind = tree.query(pos_np, k = k + 1, return_distance=False)  # k+1 because includes self\n",
    "    # Convert neighbors to edge index\n",
    "    row_idx = np.repeat(np.arange(N), k)\n",
    "    col_idx = ind[:, 1:].reshape(-1)  # exclude self neighbor at index 0\n",
    "    edge_index = torch.tensor([row_idx, col_idx], dtype=torch.long)\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:28.455247Z",
     "iopub.status.busy": "2025-06-03T10:52:28.455063Z",
     "iopub.status.idle": "2025-06-03T10:52:28.46964Z",
     "shell.execute_reply": "2025-06-03T10:52:28.468989Z",
     "shell.execute_reply.started": "2025-06-03T10:52:28.45523Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def assign_feat(x, feat, tomo_id, vol_size): # normalization back to feature's  dimension\n",
    "    d, h, w = vol_size\n",
    "    fd, fh, fw = feat.shape[0], feat.shape[2], feat.shape[3]\n",
    "    z = x[:, 0].astype('int32')\n",
    "    y = ((x[:, 1]/h) * fh).astype('int32')\n",
    "    x = ((x[:, 2]/w) * fw).astype('int32')\n",
    "    extract_feat = feat[z, :, y, x]\n",
    "    return extract_feat\n",
    "\n",
    "def sample_uniform_3d_ball(info, tomo_id, vol_size, radius=30, num_samples=20):\n",
    "    \"\"\"\n",
    "    Uniformly sample points in 3D balls around each point without exceeding volume boundary.\n",
    "\n",
    "    2. vec /= np.linalg.norm(vec, axis=1, keepdims=True)\n",
    "    Normalizes each row (each vector) to unit length → now each vector lies on the unit sphere.\n",
    "    Still shape: (n, 3)\n",
    "\n",
    "    So now vec contains n unit direction vectors randomly distributed on the surface of the unit sphere.\n",
    "\n",
    "    3. r = np.random.rand(n) ** (1/3)\n",
    "    Generates n random radii from a uniform distribution inside a sphere.  To account for the fact that volume increases with r³, so we invert it for uniform volume density.\n",
    "    Shape: (n,)\n",
    "\n",
    "    4. r[:, None] (n,) → (n, 1)\n",
    "\n",
    "    5. vec * (r[:, None] * radius) Multiplies each unit direction vector by a scaled radius.\n",
    "\n",
    "    Shape: (n, 3) → each row is a 3D point.\n",
    "        Args:\n",
    "            points (np.ndarray): (N, 3) center points\n",
    "            radius (float): radius of ball\n",
    "            num_samples (int): number of samples per center\n",
    "            volume_shape (tuple): (Z, Y, X) shape of 3D volume\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: (N, num_samples, 3) sampled points clipped to stay in volume\n",
    "    \"\"\"\n",
    "    Z, Y, X = vol_size\n",
    "\n",
    "    points = info[:, :-1] # get all the x y z\n",
    "    N = points.shape[0] # numbner of points \n",
    "\n",
    "    def uniform_ball(n):\n",
    "        vec = np.random.randn(n, 3)        #✅ Why keepdims=True? array of the norms (n,) → (n, 1)\n",
    "        vec /= np.linalg.norm(vec, axis=1, keepdims=True) # “Compute the norm across columns (i.e., across the 3D components of each point).” => a shape (n,)  \n",
    "                                # axis=0 = down the rows → column-wise ops\n",
    "                                # axis=1 = across the columns → row-wise ops\n",
    "        r = np.random.rand(n) ** (1/3) # → shape = (20, 1) \n",
    "        return vec * (r[:, None] * radius)  # (20, 3) = (20, 1) × (20, 3) element-wise scalar multiplication via broadcasting\n",
    "\n",
    "    result = []\n",
    "    np.random.seed(42)\n",
    "    for center in points:\n",
    "        attempts = 0\n",
    "        accepted = []\n",
    "\n",
    "        # Accept valid samples until we have enough or hit retry limit\n",
    "        while len(accepted) < num_samples and attempts < num_samples * 10:\n",
    "            samples = uniform_ball(num_samples)\n",
    "            candidates = samples + center  # shifted samples\n",
    "\n",
    "            # Keep only those within volume bounds\n",
    "            mask = (\n",
    "                (candidates[:, 0] >= 0) & (candidates[:, 0] < Z) &\n",
    "                (candidates[:, 1] >= 0) & (candidates[:, 1] < Y) &\n",
    "                (candidates[:, 2] >= 0) & (candidates[:, 2] < X)\n",
    "            )\n",
    "            accepted.extend(candidates[mask])\n",
    "            attempts += 1\n",
    "\n",
    "        # If not enough valid, pad with center point\n",
    "        if len(accepted) < num_samples:\n",
    "            accepted.extend([center] * (num_samples - len(accepted)))\n",
    "\n",
    "        result.append(np.array(accepted[:num_samples]))\n",
    "\n",
    "    result = np.concatenate(result, axis=0)\n",
    "    return result\n",
    "\n",
    "\n",
    "transform_ = AddRandomWalkPE(walk_length=MODEL_CONIFG_1.walk_length, attr_name=None)\n",
    "\n",
    "def extract_tomo(info, feat, tomo_id, radius, num_samples):\n",
    "    tomo_dir = os.path.join(test_dir, tomo_id)\n",
    "    tomo_names = os.listdir(tomo_dir)\n",
    "    D = len(tomo_names)\n",
    "    img = cv2.imread(os.path.join(tomo_dir, tomo_names[0]))\n",
    "    H, W = img.shape[:2]\n",
    "    del img\n",
    "    vol_size = [D, H, W]\n",
    "    points = sample_uniform_3d_ball(info, tomo_id, vol_size, radius = 30, num_samples= 20) # ball randomized \n",
    "    extract_feat = assign_feat(points, feat, tomo_id, vol_size)   # normalization back to feature's  dimension\n",
    "    #convert to torch\n",
    "    points = torch.from_numpy(points)\n",
    "    extract_feat = torch.from_numpy(extract_feat)\n",
    "    batch = torch.zeros(points.shape[0], dtype=torch.int64)\n",
    "\n",
    "    #multi-graph\n",
    "    edge_index_1 = knn_graph(points, k=12, loop=False)\n",
    "    # points_noisy = points + torch.randn_like(points) * 0.01  # small Gaussian noise\n",
    "    # edge_index_2 = knn_graph(points_noisy, k=10, loop=False)\n",
    "    edge_index_2 = knn_graph(points, k=12, loop=False)\n",
    "    # tensor([\n",
    "    # [10, 17, 14, 11,  3,  ...],  # Source node indices\n",
    "    # [ 0,  0,  0,  1,  1,  ...]   # Target node indices\n",
    "\n",
    "    \n",
    "    edge_index_3 = delaunay_graph(points)\n",
    "    data1= Data(points = points, x = extract_feat, edge_index = edge_index_1, batch = batch)\n",
    "    data2= Data(points = points, x = extract_feat, edge_index = edge_index_2, batch = batch)\n",
    "    data3= Data(points = points, x = extract_feat, edge_index = edge_index_3, batch = batch)\n",
    "\n",
    "    data1 = transform_(data1)\n",
    "    data2 = transform_(data2)\n",
    "    data3 = transform_(data3)\n",
    "    return data1, data2, data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:28.470518Z",
     "iopub.status.busy": "2025-06-03T10:52:28.470292Z",
     "iopub.status.idle": "2025-06-03T10:52:28.490033Z",
     "shell.execute_reply": "2025-06-03T10:52:28.48945Z",
     "shell.execute_reply.started": "2025-06-03T10:52:28.4705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GraphModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.gnn = GraphSAGE(384 + cfg.walk_length if cfg.use_pe else 384,\n",
    "                             num_layers= cfg.num_layers,\n",
    "                             hidden_channels=cfg.hidden_channels,\n",
    "                             out_channels=1,\n",
    "                             jk=cfg.jk,\n",
    "                             dropout=cfg.dropout,\n",
    "                             norm=LayerNorm(cfg.hidden_channels),\n",
    "                             )\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        edge_index = edge_index.cuda()\n",
    "        batch = batch.cuda()\n",
    "\n",
    "        if edge_index.shape[0] == 0:\n",
    "            edge_index = torch.tensor([[0, 0]]).T.cuda()\n",
    "\n",
    "        x = x.cuda()\n",
    "        logits = self.gnn(x, edge_index, batch=batch)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **》》》 Inference&Submission**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GPU Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:28.491051Z",
     "iopub.status.busy": "2025-06-03T10:52:28.49077Z",
     "iopub.status.idle": "2025-06-03T10:52:28.531314Z",
     "shell.execute_reply": "2025-06-03T10:52:28.530712Z",
     "shell.execute_reply.started": "2025-06-03T10:52:28.491023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GPUProfiler:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.start_time = None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        self.start_time = time.time()\n",
    "        return self\n",
    "        \n",
    "    def __exit__(self, *args):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        elapsed = time.time() - self.start_time\n",
    "        # print(f\"[PROFILE] {self.name}: {elapsed:.3f}s\")\n",
    "\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "if device.startswith('cuda'):\n",
    "    # Set CUDA optimization flags\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True  # Allow TF32 on Ampere GPUs\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    # Print GPU info\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert to GB\n",
    "    print(f\"Using GPU: {gpu_name} with {gpu_mem:.2f} GB memory\")\n",
    "    \n",
    "    # Get available GPU memory and set batch size accordingly\n",
    "    free_mem = gpu_mem - torch.cuda.memory_allocated(0) / 1e9\n",
    "    BATCH_SIZE = max(8, min(32, int(free_mem * 4)))  # 4 images per GB as rough estimate\n",
    "    print(f\"Dynamic batch size set to {BATCH_SIZE} based on {free_mem:.2f}GB free memory\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "    BATCH_SIZE = 4  # Reduce batch size for CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:28.532187Z",
     "iopub.status.busy": "2025-06-03T10:52:28.531977Z",
     "iopub.status.idle": "2025-06-03T10:52:28.535239Z",
     "shell.execute_reply": "2025-06-03T10:52:28.53433Z",
     "shell.execute_reply.started": "2025-06-03T10:52:28.532168Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import hdbscan\n",
    "# from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:28.536303Z",
     "iopub.status.busy": "2025-06-03T10:52:28.536064Z",
     "iopub.status.idle": "2025-06-03T10:52:28.548582Z",
     "shell.execute_reply": "2025-06-03T10:52:28.547871Z",
     "shell.execute_reply.started": "2025-06-03T10:52:28.536279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# #lower: accept noise\n",
    "# #higher: discard noise \n",
    "# min_cluster_size = 2\n",
    "# min_samples = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:28.549553Z",
     "iopub.status.busy": "2025-06-03T10:52:28.549363Z",
     "iopub.status.idle": "2025-06-03T10:52:28.561886Z",
     "shell.execute_reply": "2025-06-03T10:52:28.56122Z",
     "shell.execute_reply.started": "2025-06-03T10:52:28.549536Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# #hdbscan\n",
    "# def postprocessing(points):\n",
    "#     clusterer = hdbscan.HDBSCAN(min_cluster_size = min_cluster_size,\n",
    "#                                 min_samples = min_samples)\n",
    "#     labels = clusterer.fit_predict(points)\n",
    "#     clusters = defaultdict(list)\n",
    "#     for label, point in zip(labels, points):\n",
    "#         if label != -1: \n",
    "#             clusters[label].append(point)\n",
    "#     voted_keypoints = [\n",
    "#         tuple(np.mean(points, axis=0))\n",
    "#         for points in clusters.values()\n",
    "#     ]\n",
    "#     cluster_size = [len(points) for points in clusters.values()]\n",
    "#     print(cluster_size)\n",
    "#     idx = np.argmax(cluster_size)\n",
    "#     return voted_keypoints[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:28.562861Z",
     "iopub.status.busy": "2025-06-03T10:52:28.562591Z",
     "iopub.status.idle": "2025-06-03T10:52:28.589885Z",
     "shell.execute_reply": "2025-06-03T10:52:28.589217Z",
     "shell.execute_reply.started": "2025-06-03T10:52:28.562831Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def normalize_slice(slice_data):\n",
    "    \"\"\"\n",
    "    Normalize slice data using 2nd and 98th percentiles for better contrast\n",
    "    \"\"\"\n",
    "    p2 = np.percentile(slice_data, 2)\n",
    "    p98 = np.percentile(slice_data, 98)\n",
    "    clipped_data = np.clip(slice_data, p2, p98)\n",
    "    normalized = 255 * (clipped_data - p2) / (p98 - p2)\n",
    "    return np.uint8(normalized)\n",
    "\n",
    "def preload_image_batch(file_paths):\n",
    "    \"\"\"Preload a batch of images to CPU memory\"\"\"\n",
    "    images = []\n",
    "    for path in file_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            # Try with PIL as fallback\n",
    "            img = np.array(Image.open(path))\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "def process_tomogram(tomo_id, model, model_gnns_1, model_gnns_2, index=0, total=1):\n",
    "    \"\"\"\n",
    "    Process a single tomogram and return the most confident motor detection\n",
    "    \"\"\"\n",
    "    # print(f\"Processing tomogram {tomo_id} ({index}/{total})\")\n",
    "    \n",
    "    # Get all slice files for this tomogram\n",
    "    tomo_dir = os.path.join(test_dir, tomo_id)\n",
    "    slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
    "    \n",
    "    # Apply CONCENTRATION to reduce the number of slices processed\n",
    "    # This will process approximately CONCENTRATION fraction of all slices\n",
    "    selected_indices = np.linspace(0, len(slice_files)-1, int(len(slice_files) * CONCENTRATION))\n",
    "    selected_indices = np.round(selected_indices).astype(int)\n",
    "    slice_files = [slice_files[i] for i in selected_indices]\n",
    "    \n",
    "\n",
    "    all_detections = []\n",
    "    all_detections_tmp = []\n",
    "    all_features_bifpn = []\n",
    "    if device.startswith('cuda'):\n",
    "        streams = [torch.cuda.Stream() for _ in range(min(4, BATCH_SIZE))]\n",
    "    else:\n",
    "        streams = [None]\n",
    "    \n",
    "    # Variables for preloading\n",
    "    next_batch_thread = None\n",
    "    next_batch_images = None\n",
    "    \n",
    "    # Process slices in batches\n",
    "    for batch_start in tqdm(range(0, len(slice_files), BATCH_SIZE)):\n",
    "        # Wait for previous preload thread if it exists\n",
    "        if next_batch_thread is not None:\n",
    "            next_batch_thread.join()\n",
    "            next_batch_images = None\n",
    "            \n",
    "        batch_end = min(batch_start + BATCH_SIZE, len(slice_files))\n",
    "        batch_files = slice_files[batch_start:batch_end]\n",
    "        \n",
    "        # Start preloading next batch\n",
    "        next_batch_start = batch_end\n",
    "        next_batch_end = min(next_batch_start + BATCH_SIZE, len(slice_files))\n",
    "        next_batch_files = slice_files[next_batch_start:next_batch_end] if next_batch_start < len(slice_files) else []\n",
    "        \n",
    "        if next_batch_files:\n",
    "            next_batch_paths = [os.path.join(tomo_dir, f) for f in next_batch_files]\n",
    "            next_batch_thread = threading.Thread(target=preload_image_batch, args=(next_batch_paths,))\n",
    "            next_batch_thread.start()\n",
    "        else:\n",
    "            next_batch_thread = None\n",
    "        \n",
    "        # Split batch across streams for parallel processing\n",
    "        sub_batches = np.array_split(batch_files, len(streams))\n",
    "        sub_batch_results = []\n",
    "        \n",
    "        for i, sub_batch in enumerate(sub_batches):\n",
    "            if len(sub_batch) == 0:\n",
    "                continue\n",
    "                \n",
    "            stream = streams[i % len(streams)]\n",
    "            with torch.cuda.stream(stream) if stream and device.startswith('cuda') else nullcontext():\n",
    "                # Process sub-batch\n",
    "                sub_batch_paths = [os.path.join(tomo_dir, slice_file) for slice_file in sub_batch]\n",
    "                sub_batch_slice_nums = [int(slice_file.split('_')[1].split('.')[0]) for slice_file in sub_batch]\n",
    "                \n",
    "                # Run inference with profiling\n",
    "                with GPUProfiler(f\"Inference batch {i+1}/{len(sub_batches)}\"):\n",
    "                    with torch.no_grad():\n",
    "                        features = get_feature_map(model)\n",
    "                        sub_results = model.predict(sub_batch_paths, imgsz=960, verbose=False)\n",
    "                bifpn_feat = features['bifpn'].cpu().numpy()\n",
    "                all_features_bifpn.append(bifpn_feat)\n",
    "                del bifpn_feat\n",
    "                \n",
    "                # Process each result in this sub-batch\n",
    "                for j, result in enumerate(sub_results):\n",
    "                    if len(result.boxes) > 0:\n",
    "                        boxes = result.boxes\n",
    "                        for box_idx, confidence in enumerate(boxes.conf):\n",
    "                            if confidence >= GNN_THR:\n",
    "                                # Get bounding box coordinates\n",
    "                                x1, y1, x2, y2 = boxes.xyxy[box_idx].cpu().numpy()\n",
    "                                \n",
    "                                # Calculate center coordinates\n",
    "                                x_center = (x1 + x2) / 2\n",
    "                                y_center = (y1 + y2) / 2\n",
    "\n",
    "                                all_detections_tmp.append([round(sub_batch_slice_nums[j]),\n",
    "                                                           round(y_center),\n",
    "                                                           round(x_center),\n",
    "                                                           float(confidence)\n",
    "                                                          ])\n",
    "                                \n",
    "                                if confidence >= YOLO_THR:\n",
    "                                    all_detections.append({\n",
    "                                        'z': round(sub_batch_slice_nums[j]),\n",
    "                                        'y': round(y_center),\n",
    "                                        'x': round(x_center),\n",
    "                                        'confidence': float(confidence)\n",
    "                                    })\n",
    "        \n",
    "        # Synchronize streams\n",
    "        if device.startswith('cuda'):\n",
    "            torch.cuda.synchronize()\n",
    "    \n",
    "    # Clean up thread if still running\n",
    "    if next_batch_thread is not None:\n",
    "        next_batch_thread.join()\n",
    "\n",
    "    if len(all_detections)==0:\n",
    "        return {\n",
    "            'tomo_id': tomo_id,\n",
    "            'Motor axis 0': -1,\n",
    "            'Motor axis 1': -1,\n",
    "            'Motor axis 2': -1\n",
    "        }\n",
    "\n",
    "    all_detections_tmp = np.array(all_detections_tmp)\n",
    "    all_features_bifpn = np.concatenate(all_features_bifpn, axis=0)\n",
    "    data1, data2, data3 = extract_tomo(all_detections_tmp, all_features_bifpn, tomo_id, 30, 20) # get GNN train model                   # Data(points = points, x = extract_feat, edge_index = edge_index_1, batch = batch)\n",
    "                                                                                                # ball randomized                       # BaseData, FeatureStore, GraphStore\n",
    "                                                                                                # extract_feat = assign_feat(points, feat, tomo_id, vol_size)   # normalization back to feature's  dimension\n",
    "    del all_detections_tmp\n",
    "    del all_features_bifpn\n",
    "    gc.collect()\n",
    "\n",
    "    def conf_filter(pred, conf):\n",
    "        return torch.where(pred>conf, pred, 0)\n",
    "\n",
    "    #forward\n",
    "    gnn_pred_1 = torch.stack(\n",
    "        [conf_filter(model_gnns_1[0](data1).sigmoid()[:, 0].cpu(), knn_conf[0])] +\\\n",
    "        [conf_filter(_model_gnns_1(data2).sigmoid()[:, 0].cpu(), knn_conf[i+1]) for i, _model_gnns_1 in enumerate(model_gnns_1[1:])], dim=-1) #(N, 2)\n",
    "    gnn_pred_1, _ = torch.max(gnn_pred_1, dim=-1)\n",
    "    \n",
    "    gnn_pred_2 = torch.stack(\n",
    "        [conf_filter(model_gnn(data3).sigmoid()[:, 0].cpu(), delaunay_conf[i]) for i, model_gnn in enumerate(model_gnns_2)], dim=-1)\n",
    "    gnn_pred_2, _ = torch.max(gnn_pred_2, dim=-1)\n",
    "    \n",
    "    gnn_pred = torch.cat([gnn_pred_1[gnn_pred_1>MODEL_CONIFG_1.conf],\n",
    "                          gnn_pred_2[gnn_pred_2>MODEL_CONIFG_2.conf]], dim=0).cpu()\n",
    "\n",
    "    try:\n",
    "        points_1 = data1.points[gnn_pred_1>MODEL_CONIFG_1.conf]\n",
    "        points_2 = data2.points[gnn_pred_2>MODEL_CONIFG_2.conf] + 1e-4\n",
    "        points = torch.cat([points_1, points_2], dim=0)\n",
    "        pred_idx = gnn_pred.argmax()\n",
    "        point_pred = points[pred_idx].numpy() #(3, )\n",
    "        # point_pred = postprocessing(points)\n",
    "        return {\n",
    "            'tomo_id': tomo_id,\n",
    "            'Motor axis 0': point_pred[0],\n",
    "            'Motor axis 1': point_pred[1],\n",
    "            'Motor axis 2': point_pred[2]\n",
    "        }\n",
    "    except:\n",
    "        return {\n",
    "            'tomo_id': tomo_id,\n",
    "            'Motor axis 0': -1,\n",
    "            'Motor axis 1': -1,\n",
    "            'Motor axis 2': -1\n",
    "        }\n",
    "    \n",
    "\n",
    "def debug_image_loading(tomo_id):\n",
    "    \"\"\"\n",
    "    Debug function to check image loading\n",
    "    \"\"\"\n",
    "    tomo_dir = os.path.join(test_dir, tomo_id)\n",
    "    slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
    "    \n",
    "    if not slice_files:\n",
    "        print(f\"No image files found in {tomo_dir}\")\n",
    "        return\n",
    "        \n",
    "    sample_file = slice_files[len(slice_files)//2]  # Middle slice\n",
    "    img_path = os.path.join(tomo_dir, sample_file)\n",
    "    \n",
    "    # Try different loading methods\n",
    "    try:\n",
    "        # Method 1: PIL\n",
    "        img_pil = Image.open(img_path)\n",
    "        img_array_pil = np.array(img_pil)\n",
    "        \n",
    "        # Method 2: OpenCV\n",
    "        img_cv2 = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        # print(f\"OpenCV Image shape: {img_cv2.shape}, dtype: {img_cv2.dtype}\")\n",
    "        \n",
    "        # Method 3: Convert to RGB\n",
    "        img_rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {img_path}: {e}\")\n",
    "        \n",
    "    # Also test with YOLO's built-in loader\n",
    "    try:\n",
    "        test_model = YOLO(model_path)\n",
    "        test_results = test_model([img_path], verbose=False)\n",
    "        # print(\"YOLO model successfully processed the test image\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with YOLO processing: {e}\")\n",
    "\n",
    "def load_kfold_models(cfg, fold_paths):\n",
    "    models = []\n",
    "    for path in fold_paths:\n",
    "        model_gnn = GraphModel(cfg)\n",
    "        model_gnn.load_state_dict(torch.load(path))\n",
    "        model_gnn.to(device)\n",
    "        model_gnn.eval()\n",
    "        models.append(model_gnn)\n",
    "    return models\n",
    "\n",
    "def generate_submission():\n",
    "    \"\"\"\n",
    "    Main function to generate the submission file\n",
    "    \"\"\"\n",
    "    test_tomos = sorted([d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))])\n",
    "    total_tomos = len(test_tomos)\n",
    "    \n",
    "    if test_tomos:\n",
    "        debug_image_loading(test_tomos[0])\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print('load yolo')\n",
    "    model = YOLO(model_path)\n",
    "    model.to(device)\n",
    "\n",
    "    print('load gnn')\n",
    "    model_gnns_1 = load_kfold_models(MODEL_CONIFG_1, knn_folds)\n",
    "    model_gnns_2 = load_kfold_models(MODEL_CONIFG_2, delaunay_folds)\n",
    "\n",
    "    print('start inference')\n",
    "    # Additional optimizations for inference\n",
    "    if device.startswith('cuda'):\n",
    "        # Fuse conv and bn layers for faster inference\n",
    "        model.fuse()\n",
    "        \n",
    "        # Enable model half precision (FP16) if on compatible GPU\n",
    "        if torch.cuda.get_device_capability(0)[0] >= 7:  # Volta or newer\n",
    "            model.model.half()\n",
    "    \n",
    "    # Process tomograms with parallelization\n",
    "    results = []\n",
    "    motors_found = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        future_to_tomo = {}\n",
    "        \n",
    "        # Submit all tomograms for processing\n",
    "        for i, tomo_id in enumerate(test_tomos, 1):\n",
    "            future = executor.submit(process_tomogram, tomo_id, model, model_gnns_1, model_gnns_2, i, total_tomos)\n",
    "            future_to_tomo[future] = tomo_id\n",
    "        \n",
    "        # Process completed futures as they complete\n",
    "        for future in future_to_tomo:\n",
    "            tomo_id = future_to_tomo[future]\n",
    "            \n",
    "            try:\n",
    "                # Clear CUDA cache between tomograms\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "                \n",
    "                # Update motors found count\n",
    "                has_motor = not pd.isna(result['Motor axis 0'])\n",
    "                if has_motor:\n",
    "                    motors_found += 1\n",
    "                    print(f\"Motor found in {tomo_id} at position: \"\n",
    "                          f\"z={result['Motor axis 0']}, y={result['Motor axis 1']}, x={result['Motor axis 2']}\")\n",
    "                else:\n",
    "                    print(f\"No motor detected in {tomo_id}\")\n",
    "                    \n",
    "                print(f\"Current detection rate: {motors_found}/{len(results)} ({motors_found/len(results)*100:.1f}%)\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {tomo_id}: {e}\")\n",
    "                # Create a default entry for failed tomograms\n",
    "                results.append({\n",
    "                    'tomo_id': tomo_id,\n",
    "                    'Motor axis 0': -1,\n",
    "                    'Motor axis 1': -1,\n",
    "                    'Motor axis 2': -1\n",
    "                })\n",
    "    \n",
    "    # Create submission dataframe\n",
    "    submission_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Ensure proper column order\n",
    "    submission_df = submission_df[['tomo_id', 'Motor axis 0', 'Motor axis 1', 'Motor axis 2']]\n",
    "    \n",
    "    # Save the submission file\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(\"=\"*50)\n",
    "    print(\"= Submission preview:\")\n",
    "    print(\"=\"*50)\n",
    "    print(submission_df.head())\n",
    "    \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:52:28.590864Z",
     "iopub.status.busy": "2025-06-03T10:52:28.590636Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = generate_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11294684,
     "sourceId": 91249,
     "sourceType": "competition"
    },
    {
     "datasetId": 6873934,
     "sourceId": 11036126,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6880023,
     "sourceId": 11044741,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6989638,
     "sourceId": 11195676,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6899986,
     "sourceId": 11522950,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7238009,
     "sourceId": 11947116,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7235188,
     "sourceId": 11978661,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7536393,
     "sourceId": 12046199,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 219146636,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 227202990,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
